{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1toJmW-Ejwtk6kppqX87hYpBeC8gzG8rX","authorship_tag":"ABX9TyMwc06i7eVkgFspefmDZOPH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RSd0M_M_edsj","colab_type":"code","outputId":"cf2b276d-eeca-493a-d76e-8d3eeaedf58e","executionInfo":{"status":"ok","timestamp":1585816530928,"user_tz":-480,"elapsed":4632,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["!pip install transformers\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wgCS5AQaMmqP","colab_type":"code","colab":{}},"source":["import os\n","path = \"/content/drive/My Drive/NLP/sentiment_compete\"\n","os.chdir(path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8flkPTReytz","colab_type":"code","colab":{}},"source":["import torch\n","import pandas as pd\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5aem1Eue9V0","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer,BertConfig\n","from transformers import BertModel\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0xfUnGrNga7","colab_type":"code","colab":{}},"source":["train_file_path = 'data/train_weibo_clean.csv'\n","train09_file_path = 'data/train_weibo_09.csv'\n","dev01_file_path = 'data/train_weibo_01.csv'\n","bert_model_path = 'bert_base_chinese/bert-base-chinese-pytorch_model.bin'\n","bert_config_path = 'bert_base_chinese/bert-base-chinese-config.json'\n","bert_vocab_path = 'bert_base_chinese/bert-base-chinese-vocab.txt'\n","max_seq_len = 140\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOWepvm4dexx","colab_type":"code","outputId":"94c48374-e891-4855-da32-b477e763f193","executionInfo":{"status":"ok","timestamp":1585816578631,"user_tz":-480,"elapsed":1133,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bert_config = BertConfig.from_pretrained(bert_config_path, output_hidden_states=True)\n","tokenizer = BertTokenizer.from_pretrained(bert_vocab_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WfMhXcXaXC01","colab_type":"code","colab":{}},"source":["def split_data(file_path, rate=0.9):\n","  df = pd.read_csv(file_path)\n","  df = df.iloc[np.random.permutation(len(df))]\n","  train_df = df.iloc[:int(len(df)*rate)]\n","  dev_df = df.iloc[int(len(df)*rate):]\n","  train_df.to_csv('data/train_weibo_09.csv', index=False)\n","  dev_df.to_csv('data/train_weibo_01.csv', index=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Onypl-63M7Db","colab_type":"code","colab":{}},"source":["def load_data(file_path, tokenizer, max_seq_len, device):\n","  df = pd.read_csv(file_path)\n","  df = df[df['情感倾向'].isin(['0', '1','-1'])]\n","  df = df[['微博中文内容', '情感倾向']]\n","  inputs = tokenize_data(df, tokenizer, '微博中文内容', max_seq_len, device)\n","  outputs = torch.tensor(data=df['情感倾向'].astype(int) + 1, dtype=torch.long, device=device)\n","  return inputs, outputs\n","\n","def tokenize_data(df, tokenizer, column, max_seq_len, device):\n","  input_ids = []\n","  attention_mask = []\n","  token_type_ids = []\n","  for content in tqdm(df[column]):\n","    inputs = tokenizer.encode_plus(text=str(content),\n","                    add_special_tokens=True,\n","                    max_length=max_seq_len,\n","                    truncation_strategy=\"longest_first\",\n","                    return_attention_mask=True,\n","                    pad_to_max_length=True)\n","    ids, masks, token_type_id = inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids']\n","    input_ids.append(ids)\n","    attention_mask.append(masks)\n","    token_type_ids.append(token_type_id) # 3 n len\n","  return torch.tensor(data=[input_ids, attention_mask, token_type_ids], device=device).permute(1, 0, 2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XkxYXyaCfFvg","colab_type":"code","outputId":"1875e2cb-bf7a-4dd7-c586-f4da0e358391","executionInfo":{"status":"ok","timestamp":1585817199287,"user_tz":-480,"elapsed":47636,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_data = load_data(train09_file_path, tokenizer, max_seq_len, device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 89604/89604 [00:43<00:00, 2037.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kIsz-quGblu2","colab_type":"code","outputId":"e766e70d-439f-4da4-ba0e-d2a62862b9a6","executionInfo":{"status":"ok","timestamp":1585817204650,"user_tz":-480,"elapsed":52829,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dev_data = load_data(dev01_file_path, tokenizer, max_seq_len, device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 9956/9956 [00:04<00:00, 2038.08it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qF8Z2FfdsrFz","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","\n","\n","class BertCLSLAST3MEAN(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(BertCLSLAST3MEAN, self).__init__()\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.predict_fc = nn.Sequential(nn.Dropout(p=0.2),\n","                        nn.Linear(config.hidden_size * 2, config.hidden_size),\n","                        nn.Tanh(),\n","                        nn.Dropout(p=0.2),\n","                        nn.Linear(config.hidden_size, 3)\n","                        )\n","        self.predict_fc.apply(self.init_network)\n","        #for param in self.bert_model.parameters():\n","        #    param.requires_grad = False\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, inputs):\n","        #(batch_size, 3, seq_max_len)i\n","        input_ids = inputs[:, 0] # (batch_size, seq_max_len)\n","        attention_mask = inputs[:, 1] # (batch_size, seq_max_len)\n","        token_type_ids = inputs[:, 2] # (batch_size, seq_max_len)\n","        #(batch_size, sequence_length, hidden_size)\n","        sequence_output, pooler_output, hidden_states = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        attention_mask_pad = attention_mask.unsqueeze(2).permute(0, 2, 1) # (batch_size, 1, seq_len)\n","        \n","        seq_lens = torch.sum(attention_mask, dim=1).unsqueeze(1)# (batch_size, 1)\n","       \n","        #h13 = self.get_mean(attention_mask_pad, hidden_states[-1], seq_lens)# (batch_size, hidden_size)\n","        \"\"\"\n","        h12 = self.get_mean(attention_mask_pad, hidden_states[-2], seq_lens)# (batch_size, hidden_size)\n","        h11 = self.get_mean(attention_mask_pad, hidden_states[-3], seq_lens)# (batch_size, hidden_size)\n","        h10 = self.get_mean(attention_mask_pad, hidden_states[-4], seq_lens)# (batch_size, hidden_size)\n","        concat_hidden = torch.cat([h13, h12, h11, h10], dim=1)#(batch_size, 4, hidden_size)\n","        \"\"\"\n","        #h13 = h13.squeeze()\n","        #mean_hidden = concat_hidden.mean(dim=1)#(batch_size, hidden_size)\n","        mean_cls = (hidden_states[-1][:,0] + hidden_states[-2][:,0] + hidden_states[-3][:,0]) / 3.0\n","        concat_input = torch.cat([pooler_output, mean_cls], dim=1)\n","        outputs = self.predict_fc(concat_input)\n","        return outputs\n","\n","    def get_mean(self, attention_mask_pad, hidden_state, seq_lens):\n","        \"\"\"\n","          hidden_state: (batch_size, seq_len, hidden_size)\n","          seq_lens (batch_size, 1)\n","        \"\"\"\n","        hidden_state_real = hidden_state.permute(0, 2, 1) * attention_mask_pad # (batch_size, hidden_size, seq_len)\n","        hidden_state_real = hidden_state_real.permute(0, 2, 1)# (batch_size, seq_len, hidden_size)\n","        hidden_state_sum = torch.sum(hidden_state_real, dim=1)# (batch_size, hidden_size)\n","        return self.div_with_small_value(hidden_state_sum, seq_lens).unsqueeze(1)\n","\n","    def div_with_small_value(self, a, b, eps=1.0):\n","        b = b * (b > eps).float() + (b <= eps).float() * 1.0\n","        return a / b \n","\n","    def init_network(self, module):\n","        if isinstance(module, nn.Linear):\n","          print(module.__class__.__name__)\n","          nn.init.xavier_uniform_(module.weight.data)\n","          nn.init.constant_(module.bias.data, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqkAAr4f2ZQB","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","\n","\n","class BertCLSLAST3(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(BertCLSLAST3, self).__init__()\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.predict_fc = nn.Sequential(nn.Dropout(p=0.2),\n","                        nn.Linear(config.hidden_size * 2, config.hidden_size),\n","                        nn.Tanh(),\n","                        nn.Dropout(p=0.2),\n","                        nn.Linear(config.hidden_size, 3)\n","                        )\n","        self.predict_fc.apply(self.init_network)\n","        #for param in self.bert_model.parameters():\n","        #    param.requires_grad = False\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, inputs):\n","        #(batch_size, 3, seq_max_len)i\n","        input_ids = inputs[:, 0] # (batch_size, seq_max_len)\n","        attention_mask = inputs[:, 1] # (batch_size, seq_max_len)\n","        token_type_ids = inputs[:, 2] # (batch_size, seq_max_len)\n","        #(batch_size, sequence_length, hidden_size)\n","        sequence_output, pooler_output, hidden_states = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        attention_mask_pad = attention_mask.unsqueeze(2).permute(0, 2, 1) # (batch_size, 1, seq_len)\n","        seq_lens = torch.sum(attention_mask, dim=1).unsqueeze(1)# (batch_size, 1)\n","        h13 = self.get_mean(attention_mask_pad, hidden_states[-1], seq_lens)# (batch_size, hidden_size)\n","        h12 = self.get_mean(attention_mask_pad, hidden_states[-2], seq_lens)# (batch_size, hidden_size)\n","        h11 = self.get_mean(attention_mask_pad, hidden_states[-3], seq_lens)# (batch_size, hidden_size)\n","        h10 = self.get_mean(attention_mask_pad, hidden_states[-4], seq_lens)# (batch_size, hidden_size)\n","        concat_hidden = torch.cat([h13, h12, h11, h10], dim=1)#(batch_size, 4, hidden_size)\n","        mean_hidden = concat_hidden.mean(dim=1)#(batch_size, hidden_size)\n","        mean_cls = (hidden_states[-1][:,0] + hidden_states[-2][:,0] + hidden_states[-3][:,0]) / 3.0\n","        concat_input = torch.cat([mean_hidden, mean_cls], dim=1)\n","        outputs = self.predict_fc(concat_input)\n","        return outputs\n","\n","    def get_mean(self, attention_mask_pad, hidden_state, seq_lens):\n","        \"\"\"\n","          hidden_state: (batch_size, seq_len, hidden_size)\n","          seq_lens (batch_size, 1)\n","        \"\"\"\n","        hidden_state_real = hidden_state.permute(0, 2, 1) * attention_mask_pad # (batch_size, hidden_size, seq_len)\n","        hidden_state_real = hidden_state_real.permute(0, 2, 1)# (batch_size, seq_len, hidden_size)\n","        hidden_state_sum = torch.sum(hidden_state_real, dim=1)# (batch_size, hidden_size)\n","        return self.div_with_small_value(hidden_state_sum, seq_lens).unsqueeze(1)\n","\n","    def div_with_small_value(self, a, b, eps=1.0):\n","        b = b * (b > eps).float() + (b <= eps).float() * 1.0\n","        return a / b \n","\n","    def init_network(self, module):\n","        if isinstance(module, nn.Linear):\n","          print(module.__class__.__name__)\n","          nn.init.xavier_uniform_(module.weight.data)\n","          nn.init.constant_(module.bias.data, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V3K8Q9N4Irq_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","\n","\n","class ModelH(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(ModelH, self).__init__()\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.predict_fc = nn.Linear(in_features=config.hidden_size, out_features=3, bias=True)\n","        self.predict_fc.apply(self.init_network)\n","        #for param in self.bert_model.parameters():\n","        #    param.requires_grad = False\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, inputs):\n","        #(batch_size, 3, seq_max_len)i\n","        input_ids = inputs[:, 0] # (batch_size, seq_max_len)\n","        attention_mask = inputs[:, 1] # (batch_size, seq_max_len)\n","        token_type_ids = inputs[:, 2] # (batch_size, seq_max_len)\n","        #(batch_size, sequence_length, hidden_size)\n","        sequence_output, pooler_output, hidden_states = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        attention_mask_pad = attention_mask.unsqueeze(2).permute(0, 2, 1) # (batch_size, 1, seq_len)\n","        #print(\"attention_mask_pad size\", attention_mask_pad.size())\n","        seq_lens = torch.sum(attention_mask, dim=1).unsqueeze(1)# (batch_size, 1)\n","        # hidden_states([64, 140, 768])\n","        h13 = self.get_mean(attention_mask_pad, hidden_states[-1], seq_lens)# (batch_size, hidden_size)\n","        h12 = self.get_mean(attention_mask_pad, hidden_states[-2], seq_lens)# (batch_size, hidden_size)\n","        h11 = self.get_mean(attention_mask_pad, hidden_states[-3], seq_lens)# (batch_size, hidden_size)\n","        h10 = self.get_mean(attention_mask_pad, hidden_states[-4], seq_lens)# (batch_size, hidden_size)\n","        #print('hidden size', h10.size())\n","        concat_hidden = torch.cat([h13, h12, h11, h10], dim=1)#(batch_size, 4, hidden_size)\n","        #print('concat_hidden size', concat_hidden.size())\n","        mean_hidden = concat_hidden.mean(dim=1)#(batch_size, hidden_size)\n","        #print('mean hidden size', mean_hidden.size())\n","        inputs_fc = self.dropout(mean_hidden)\n","        outputs = self.predict_fc(inputs_fc)\n","        return outputs\n","\n","    def get_mean(self, attention_mask_pad, hidden_state, seq_lens):\n","        \"\"\"\n","          hidden_state: (batch_size, seq_len, hidden_size)\n","          seq_lens (batch_size, 1)\n","        \"\"\"\n","        hidden_state_real = hidden_state.permute(0, 2, 1) * attention_mask_pad # (batch_size, hidden_size, seq_len)\n","        hidden_state_real = hidden_state_real.permute(0, 2, 1)# (batch_size, seq_len, hidden_size)\n","        hidden_state_sum = torch.sum(hidden_state_real, dim=1)# (batch_size, hidden_size)\n","        return self.div_with_small_value(hidden_state_sum, seq_lens).unsqueeze(1)\n","\n","    def div_with_small_value(self, a, b, eps=1.0):\n","        b = b * (b > eps).float() + (b <= eps).float() * 1.0\n","        return a / b \n","\n","    def init_network(self, module):\n","        if isinstance(module, nn.Linear):\n","          print(module.__class__.__name__)\n","          nn.init.xavier_uniform_(module.weight.data)\n","          nn.init.constant_(module.bias.data, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFvdCvYRghhv","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","import torch\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(Model, self).__init__()\n","\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.linear_1 = nn.Linear(in_features=seq_len, out_features=1, bias=True)\n","        self.linear_2 = nn.Linear(in_features=config.hidden_size * 2, out_features=3, bias=True)\n","        self.dropout = nn.Dropout(0.15)\n","        self.init_network()\n","        # for param in self.bert_model.parameters():\n","        #     param.requires_grad = False\n"," \n","\n","    def forward(self, inputs):\n","        sequence_output, pooler_output, hidden_states  = self.bert_model(input_ids=inputs[:, 0], attention_mask=inputs[:, 1], token_type_ids=inputs[:, 2])\n","        outputs = self.linear_1(sequence_output.permute(0, 2, 1)).squeeze(dim=2)\n","        # (batch_size, sequence_length, hidden_size)-> (batch_size, hidden_size)\n","        outputs = F.relu(outputs)\n","        outputs = self.dropout(outputs)\n","        concat = torch.cat([h13, h12, h11, h10], dim=1)\n","        outputs = self.linear_2(outputs)  # (batch_size, hidden_size)->(batch_size,3)\n","        outputs = F.softmax(outputs, dim=1)\n","        return outputs\n","\n","    def init_network(self):\n","        nn.init.xavier_normal_(self.linear_1.weight)\n","        nn.init.xavier_normal_(self.linear_2.weight)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiYKgjRZD8uW","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","import torch\n","\n","\n","class Model_POOL_H_ATTEN(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(Model_POOL_H_ATTEN, self).__init__()\n","\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.linear_1 = nn.Linear(in_features=seq_len, out_features=1, bias=True)\n","        self.linear_2 = nn.Linear(in_features=config.hidden_size * 2, out_features=3, bias=True)\n","        self.dropout = nn.Dropout(0.15)\n","        self.init_network()\n","        # for param in self.bert_model.parameters():\n","        #     param.requires_grad = False\n"," \n","\n","    def forward(self, inputs):\n","        sequence_output, pooler_output, hidden_states  = self.bert_model(input_ids=inputs[:, 0], attention_mask=inputs[:, 1], token_type_ids=inputs[:, 2])\n","        outputs = self.linear_1(sequence_output.permute(0, 2, 1)).squeeze(dim=2)\n","        # (batch_size, sequence_length, hidden_size)-> (batch_size, hidden_size)\n","        outputs = F.relu(outputs)\n","        outputs = self.dropout(outputs)\n","        concat = torch.cat([outputs, pooler_output], dim=1)\n","        outputs = self.linear_2(concat)  # (batch_size, hidden_size)->(batch_size,3)\n","        outputs = F.softmax(outputs, dim=1)\n","        return outputs\n","\n","    def init_network(self):\n","        nn.init.xavier_normal_(self.linear_1.weight)\n","        nn.init.xavier_normal_(self.linear_2.weight)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aksJ0yCY0Wr","colab_type":"code","colab":{}},"source":["class FocalLoss(nn.Module):\n","    def __init__(self, weight=None, reduction='mean', gamma=2, eps=1e-7):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.eps = eps\n","        self.ce = torch.nn.CrossEntropyLoss(weight=weight, reduction=reduction)\n","\n","    def forward(self, inputs, target):\n","        logp = self.ce(inputs, target)\n","        p = torch.exp(-logp)\n","        loss = (1-p) ** self.gamma * logp\n","        return loss.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7Nd41f_fkAX","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, TensorDataset\n","def train(train_data, dev_data, model, batch_size, num_epochs, model_save_path, lr=0.0001):\n","  train_inputs, train_outputs = train_data\n","  train_dataset = TensorDataset(train_inputs, train_outputs)\n","  start_time = time.time()\n","  optimizer = optim.Adam(model.parameters(), lr=lr)\n","  total_batch = 0\n","  criterion = nn.CrossEntropyLoss()\n","  dev_per_batch = 500\n","  dev_best_loss = float('inf')\n","  last_improve = 0\n","  require_improvement = 1000\n","  model.train()\n","  for epoch in range(num_epochs):\n","    print('epoch [{}/{}]'.format(epoch + 1, num_epochs))\n","    for (inputs, labels) in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n","      total_batch += 1\n","      model.zero_grad() \n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","      if total_batch % dev_per_batch == 0:\n","        true_labels = labels.data.cpu()\n","        predicts = torch.max(outputs.data, dim=1)[1].cpu().numpy()\n","        train_acc = metrics.accuracy_score(true_labels, predicts)\n","        time_dif = get_time_dif(start_time)\n","        dev_acc, dev_loss, report, confusion = evaluate(dev_data, model, batch_size)\n","        model.train()\n","        if dev_best_loss > dev_loss:\n","          dev_best_loss = dev_loss\n","          improve = '*'\n","          torch.save(model.state_dict(), model_save_path)\n","        else:\n","          improve = ' '\n","        msg = 'Epoch:{0:>2} Iter: {1:>6},  Train Loss: {2:>5.2},  Train Acc: {3:>6.2%},' \\\n","                      '  Dev Loss: {4:>5.2},  Dev Acc: {5:>6.2%},  Time: {6} {7}'\n","        print(msg.format(epoch, total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n","      \n","  evaluate(dev_data, model, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fhCtDdCgtNzJ","colab_type":"code","colab":{}},"source":["def evaluate(dev_data, model, batch_size, coef=None):\n","  model.eval()\n","  labels_all = np.array([], dtype=int)\n","  predicts_all = np.array([], dtype=int)\n","  dev_inputs, dev_outputs = dev_data\n","  criterion = nn.CrossEntropyLoss()\n","  dev_dataset = TensorDataset(dev_inputs, dev_outputs)\n","  loss_total = 0\n","  with torch.no_grad():\n","    for (inputs, labels) in DataLoader(dataset=dev_dataset, batch_size=batch_size, shuffle=False):\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss_total += loss.item()\n","        predicts = torch.max(outputs.data, dim=1)[1].cpu().numpy()\n","        labels = labels.data.cpu().numpy()\n","        predicts_all = np.append(predicts_all, predicts)\n","        labels_all = np.append(labels_all, labels)\n","  acc = metrics.accuracy_score(labels_all, predicts_all)\n","  report = metrics.classification_report(labels_all, predicts_all, digits=4)\n","  confusion = metrics.confusion_matrix(labels_all, predicts_all)\n","  return acc, loss_total / len(dev_inputs) * batch_size, report, confusion"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3cn1W33tN5Q","colab_type":"code","colab":{}},"source":["def predict(data_x, ids_all, model, coef, batch_size, output_path):\n","    model.load_state_dict(torch.load('save_model/Model_POOL_H_ATTEN'))\n","    model.eval()\n","    start_time = time.time()\n","    torch_coef = torch.tensor(coef, device=device).view(-1, 3)\n","    predicts_all = []\n","    for inputs,_ in tqdm(DataLoader(dataset=data_x, batch_size=batch_size, shuffle=False)):\n","        outputs = model(inputs)\n","        outputs = F.softmax(outputs, dim=1)\n","        outputs = outputs * torch_coef\n","        predicts = list(torch.max(outputs.data, dim=1)[1].cpu().numpy() - 1)\n","        predicts_all = predicts_all + predicts\n","\n","    time_dif = get_time_dif(start_time)\n","    print(\"Time usage:\", time_dif)\n","    result_pd = pd.DataFrame(\n","        {\n","            'id': ids_all,\n","            'y': predicts_all\n","        }\n","    )\n","    result_pd.to_csv(output_path, index=False)\n","    print(\"finish !\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fClCAWhgrsrd","colab_type":"code","colab":{}},"source":["import time\n","from datetime import timedelta\n","def get_time_dif(start_time):\n","    \"\"\"获取已使用时间\"\"\"\n","    end_time = time.time()\n","    time_dif = end_time - start_time\n","    return timedelta(seconds=int(round(time_dif)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ksNtg2nWfpCt","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn import metrics\n","import time\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wglsOoEYfyXY","colab_type":"code","colab":{}},"source":["#focal_loss = FocalLoss()\n","model = Model_POOL_H_ATTEN(bert_model_path, bert_config, 140).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4Q-0p0rjWhw","colab_type":"code","outputId":"90a0050c-6e8b-46af-f325-ab0de552bf9e","executionInfo":{"status":"error","timestamp":1585829470857,"user_tz":-480,"elapsed":9211240,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":818}},"source":["train(train_data, dev_data, model, 32, 10, 'save_model/Model_POOL_H_ATTEN', lr=0.000005)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch [1/10]\n","Epoch: 0 Iter:    500,  Train Loss:  0.69,  Train Acc: 90.62%,  Dev Loss:  0.82,  Dev Acc: 72.96%,  Time: 0:06:19 *\n","Epoch: 0 Iter:   1000,  Train Loss:  0.86,  Train Acc: 68.75%,  Dev Loss:  0.81,  Dev Acc: 73.20%,  Time: 0:14:06 *\n","Epoch: 0 Iter:   1500,  Train Loss:   0.7,  Train Acc: 84.38%,  Dev Loss:  0.81,  Dev Acc: 73.30%,  Time: 0:21:52 *\n","Epoch: 0 Iter:   2000,  Train Loss:  0.73,  Train Acc: 81.25%,  Dev Loss:   0.8,  Dev Acc: 74.20%,  Time: 0:29:38 *\n","Epoch: 0 Iter:   2500,  Train Loss:  0.78,  Train Acc: 78.12%,  Dev Loss:   0.8,  Dev Acc: 74.15%,  Time: 0:37:25 *\n","epoch [2/10]\n","Epoch: 1 Iter:   3000,  Train Loss:  0.81,  Train Acc: 75.00%,  Dev Loss:   0.8,  Dev Acc: 74.33%,  Time: 0:45:11 *\n","Epoch: 1 Iter:   3500,  Train Loss:  0.81,  Train Acc: 75.00%,  Dev Loss:   0.8,  Dev Acc: 74.64%,  Time: 0:52:58 *\n","Epoch: 1 Iter:   4000,  Train Loss:  0.84,  Train Acc: 68.75%,  Dev Loss:   0.8,  Dev Acc: 74.31%,  Time: 1:00:44  \n","Epoch: 1 Iter:   4500,  Train Loss:  0.59,  Train Acc: 96.88%,  Dev Loss:   0.8,  Dev Acc: 74.72%,  Time: 1:08:30 *\n","Epoch: 1 Iter:   5000,  Train Loss:  0.77,  Train Acc: 75.00%,  Dev Loss:   0.8,  Dev Acc: 74.38%,  Time: 1:16:17  \n","Epoch: 1 Iter:   5500,  Train Loss:  0.81,  Train Acc: 75.00%,  Dev Loss:  0.79,  Dev Acc: 75.20%,  Time: 1:24:03 *\n","epoch [3/10]\n","Epoch: 2 Iter:   6000,  Train Loss:  0.82,  Train Acc: 71.88%,  Dev Loss:  0.79,  Dev Acc: 75.32%,  Time: 1:31:50 *\n","Epoch: 2 Iter:   6500,  Train Loss:   0.8,  Train Acc: 75.00%,  Dev Loss:   0.8,  Dev Acc: 74.06%,  Time: 1:39:36  \n","Epoch: 2 Iter:   7000,  Train Loss:   0.8,  Train Acc: 75.00%,  Dev Loss:  0.79,  Dev Acc: 75.31%,  Time: 1:47:21 *\n","Epoch: 2 Iter:   7500,  Train Loss:  0.75,  Train Acc: 81.25%,  Dev Loss:  0.79,  Dev Acc: 75.50%,  Time: 1:55:07 *\n","Epoch: 2 Iter:   8000,  Train Loss:  0.77,  Train Acc: 78.12%,  Dev Loss:  0.79,  Dev Acc: 75.33%,  Time: 2:02:53 *\n","epoch [4/10]\n","Epoch: 3 Iter:   8500,  Train Loss:  0.72,  Train Acc: 81.25%,  Dev Loss:  0.79,  Dev Acc: 75.49%,  Time: 2:10:39  \n","Epoch: 3 Iter:   9000,  Train Loss:   0.8,  Train Acc: 75.00%,  Dev Loss:  0.79,  Dev Acc: 75.30%,  Time: 2:18:23  \n","Epoch: 3 Iter:   9500,  Train Loss:  0.66,  Train Acc: 90.62%,  Dev Loss:  0.79,  Dev Acc: 75.27%,  Time: 2:26:07  \n","Epoch: 3 Iter:  10000,  Train Loss:  0.73,  Train Acc: 81.25%,  Dev Loss:  0.79,  Dev Acc: 75.56%,  Time: 2:33:52  \n","Epoch: 3 Iter:  10500,  Train Loss:  0.73,  Train Acc: 81.25%,  Dev Loss:  0.79,  Dev Acc: 75.47%,  Time: 2:41:37  \n","Epoch: 3 Iter:  11000,  Train Loss:  0.83,  Train Acc: 71.88%,  Dev Loss:  0.79,  Dev Acc: 75.22%,  Time: 2:49:22  \n","epoch [5/10]\n","Epoch: 4 Iter:  11500,  Train Loss:  0.68,  Train Acc: 87.50%,  Dev Loss:  0.79,  Dev Acc: 75.69%,  Time: 2:57:06  \n","Epoch: 4 Iter:  12000,  Train Loss:  0.73,  Train Acc: 81.25%,  Dev Loss:  0.79,  Dev Acc: 75.19%,  Time: 3:04:51  \n","Epoch: 4 Iter:  12500,  Train Loss:   0.7,  Train Acc: 84.38%,  Dev Loss:   0.8,  Dev Acc: 75.13%,  Time: 3:12:36  \n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-d38694423332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'save_model/Model_POOL_H_ATTEN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-39-504860eae8a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, dev_data, model, batch_size, num_epochs, model_save_path, lr)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdev_per_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"FdWRwoSEzYm-","colab_type":"code","outputId":"554f9707-92d2-417e-a4cc-c118bc86b7b8","executionInfo":{"status":"ok","timestamp":1585829634495,"user_tz":-480,"elapsed":81758,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["dev_acc, dev_loss, report, confusion = evaluate(dev_data, model, 32)\n","print(\"report\",report)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["report               precision    recall  f1-score   support\n","\n","           0     0.6712    0.5863    0.6259      1668\n","           1     0.7730    0.8379    0.8041      5767\n","           2     0.7496    0.6684    0.7066      2521\n","\n","    accuracy                         0.7528      9956\n","   macro avg     0.7313    0.6975    0.7122      9956\n","weighted avg     0.7500    0.7528    0.7496      9956\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dEkLfg8H8Cz7","colab_type":"code","colab":{}},"source":["def load_test_data(file_path, tokenizer, max_seq_len, device):\n","  df = pd.read_csv(file_path)\n","  df = df[['微博中文内容']]\n","  inputs = tokenize_data(df, tokenizer, '微博中文内容', max_seq_len, device)\n","  return inputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qcQVx07CED45","colab_type":"code","outputId":"9648aa30-985b-4a71-d6c2-9a065a3d5c91","executionInfo":{"status":"ok","timestamp":1585816608544,"user_tz":-480,"elapsed":6234,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_input = load_test_data('data/test_weibo_clean.csv', tokenizer, max_seq_len, device)\n","test_tensor = TensorDataset(test_input, torch.rand(test_input.size()[0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:04<00:00, 2041.67it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PNsTvOQKzcUV","colab_type":"code","outputId":"ed16fab0-9795-424c-a7af-662b05bac450","executionInfo":{"status":"ok","timestamp":1585836401765,"user_tz":-480,"elapsed":87897,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["predict(test_tensor, test_df['微博id'], model, [2.88884269, 1.09375589, 2.86697647], 16, 'bert_ans.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 625/625 [01:26<00:00,  7.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["Time usage: 0:01:26\n","finish !\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UCBiyh3mBhGi","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'save_model/bert_model')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMquFJ9d5vpa","colab_type":"code","outputId":"2d8f02cf-77ed-49cc-f062-6c88094784e7","executionInfo":{"status":"ok","timestamp":1585748728852,"user_tz":-480,"elapsed":3260,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wed Apr  1 13:45:27 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    71W / 149W |  10830MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FV6ZBam24FBb","colab_type":"code","colab":{}},"source":["def get_threshold(dev_data, model, batch_size):\n","  model.eval()\n","  labels_all = np.array([], dtype=int)\n","  predicts_all = np.array([[1,1,1]], dtype=float)\n","  dev_inputs, dev_outputs = dev_data\n","  criterion = nn.CrossEntropyLoss()\n","  dev_dataset = TensorDataset(dev_inputs, dev_outputs)\n","  loss_total = 0\n","  with torch.no_grad():\n","    for (inputs, labels) in DataLoader(dataset=dev_dataset, batch_size=batch_size, shuffle=False):\n","        outputs = model(inputs)\n","        outputs = F.softmax(outputs, dim=1) \n","        predict_np = outputs.data.cpu().numpy()\n","        labels = labels.data.cpu().numpy()\n","        predicts_all = np.append(predicts_all, predict_np, axis=0)\n","        labels_all = np.append(labels_all, labels)\n","  predicts_all = predicts_all[1:]\n","  optimizedRounder = OptimizedRounder()\n","  optimizedRounder.fit(predicts_all, labels_all)\n","  coef = optimizedRounder.get_coef()\n","  return coef"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryRm6x5s6Zyg","colab_type":"code","colab":{}},"source":["predicts_all, labels_all = get_threshold(train_data, model, 32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"agLi0kUPSM1O","colab_type":"code","outputId":"13c22a7e-6daa-4151-b1d0-a852b39cd3c0","executionInfo":{"status":"ok","timestamp":1585837562691,"user_tz":-480,"elapsed":1253,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[0.21196282, 0.57606238, 0.21197481],\n","        [0.21868035, 0.54282802, 0.23849164],\n","        [0.21194977, 0.21194738, 0.57610285],\n","        ...,\n","        [0.21194674, 0.57610726, 0.21194595],\n","        [0.21195276, 0.57609522, 0.21195202],\n","        [0.21208781, 0.21242923, 0.57548296]]), array([1, 1, 2, ..., 1, 1, 2]))"]},"metadata":{"tags":[]},"execution_count":191}]},{"cell_type":"code","metadata":{"id":"LBr_nX-Q-OD0","colab_type":"code","outputId":"9ede3c05-0328-482e-cb5a-a6ddbb96efa5","executionInfo":{"status":"ok","timestamp":1585833116007,"user_tz":-480,"elapsed":1286,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(\"predicts_all shape\", predicts_all.shape)\n","print(\"labels_all shape\", labels_all.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["predicts_all shape (9956, 3)\n","labels_all shape (9956,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zv2kjv_iB6E4","colab_type":"code","colab":{}},"source":["from functools import partial\n","import numpy as np\n","import scipy as sp\n","\n","class OptimizedRounder(object):\n","    def __init__(self):\n","        self.coef_ = 0\n","\n","    def _f1_loss(self, coef, X, y):\n","        predict = X * coef\n","        predict_y = np.argmax(predict, axis =1)\n","        f1_score = metrics.f1_score(y, predict_y, average='macro')  \n","        return -f1_score * 1000\n","\n","    def fit(self, X, y):\n","        loss_partial = partial(self._f1_loss, X=X, y=y)\n","        initial_coef = [2, 1.0, 2]\n","        res= sp.optimize.basinhopping(loss_partial, initial_coef, niter=1000)\n","        print(res.x)\n","        print(res.fun)\n","        self.coef_ = res.x\n","    def get_coef(self):\n","        return self.coef_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMLzNm3V6-kA","colab_type":"code","outputId":"fdebe00b-4bd8-452e-a979-5f2f910bf170","executionInfo":{"status":"ok","timestamp":1585834735803,"user_tz":-480,"elapsed":22190,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["optimizedRounder = OptimizedRounder()\n","optimizedRounder.fit(predicts_all, labels_all)\n","coef = optimizedRounder.get_coef()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2.88884269 1.09375589 2.86697647]\n","-723.4094685948046\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7hd0lZDX7Fh5","colab_type":"code","outputId":"7993f8bd-548d-422b-9798-caa7749521e6","executionInfo":{"status":"ok","timestamp":1585834243179,"user_tz":-480,"elapsed":1175,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["coef"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.5 , 1.05, 1.  ])"]},"metadata":{"tags":[]},"execution_count":158}]},{"cell_type":"code","metadata":{"id":"dfUOmilZ7GnM","colab_type":"code","colab":{}},"source":["torch_coef = torch.tensor([2.88884269,1.09375589,2.86697647]).view(-1, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUBTeHG_IG-C","colab_type":"code","outputId":"a237be6d-f356-4e92-d650-654a8b6d6ede","executionInfo":{"status":"ok","timestamp":1585835286959,"user_tz":-480,"elapsed":1786,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch_coef"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.8888, 1.0938, 2.8670]])"]},"metadata":{"tags":[]},"execution_count":181}]},{"cell_type":"code","metadata":{"id":"FOF6wk537Y3i","colab_type":"code","outputId":"8fd9ccd4-cb72-4609-e1d3-f742b5a5973e","executionInfo":{"status":"ok","timestamp":1585832655686,"user_tz":-480,"elapsed":1447,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.argmax(d, axis =1 )"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 2])"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"-0dpPnxC-2y8","colab_type":"code","outputId":"2255bafe-3887-4c8e-ce6e-99691db264db","executionInfo":{"status":"ok","timestamp":1585834755440,"user_tz":-480,"elapsed":3869,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict_label = np.argmax(predicts_all * coef, axis =1)\n","f1_score = metrics.f1_score(labels_all, predict_label, average='macro')\n","print(f1_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.7234094685948046\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4NqtsvIoAu5v","colab_type":"code","outputId":"effe540a-3c8a-49aa-bef9-62ea475065c7","executionInfo":{"status":"ok","timestamp":1585833011768,"user_tz":-480,"elapsed":1261,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict_label.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9955,)"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"Cto3Z5fRA2Hf","colab_type":"code","colab":{}},"source":["0.7122314128155406"],"execution_count":0,"outputs":[]}]}