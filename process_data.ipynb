{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/nCoV_100k_train.labled.csv',engine ='python')\n",
    "test_df  = pd.read_csv('data/nCov_10k_test.csv',engine ='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8023e55c904d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'abcd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "temp = 'abcd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      "微博id      100000 non-null int64\n",
      "微博发布时间    100000 non-null object\n",
      "发布人账号     100000 non-null object\n",
      "微博中文内容    99646 non-null object\n",
      "微博图片      100000 non-null object\n",
      "微博视频      100000 non-null object\n",
      "情感倾向      99919 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      "微博id      10000 non-null int64\n",
      "微博发布时间    10000 non-null object\n",
      "发布人账号     10000 non-null object\n",
      "微博中文内容    9963 non-null object\n",
      "微博图片      10000 non-null object\n",
      "微博视频      10000 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['微博中文内容'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'sentiment(target)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['情感倾向'].value_counts().plot.bar()\n",
    "plt.title('sentiment(target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['情感倾向'].isin(['0','1','-1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'sentiment(target)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['情感倾向'].value_counts().plot.bar()\n",
    "plt.title('sentiment(target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['微博中文内容'].fillna(' ',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      "微博id      10000 non-null int64\n",
      "微博发布时间    10000 non-null object\n",
      "发布人账号     10000 non-null object\n",
      "微博中文内容    10000 non-null object\n",
      "微博图片      10000 non-null object\n",
      "微博视频      10000 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train_weibo_clean.csv')\n",
    "test_df.to_csv('data/test_weibo_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['微博中文内容'] = train_df['微博中文内容'].apply(str).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [写, 在, 年, 末, 冬, 初, 孩, 子, 流, 感, 的, 第, 五, 天, ，, ...\n",
       "1        [开, 年, 大, 模, 型, …, 累, 到, 以, 为, 自, 己, 发, 烧, 了, ...\n",
       "2        [, 邱, 晨, 这, 就, 是, 我, 爹, ，, 爹, ，, 发, 烧, 快, 好, ...\n",
       "3        [新, 年, 的, 第, 一, 天, 感, 冒, 又, 发, 烧, 的, 也, 太, 衰, ...\n",
       "4        [问, ：, 我, 们, 意, 念, 里, 有, 坏, 的, 想, 法, 了, ，, 天, ...\n",
       "                               ...                        \n",
       "99995    [#, 抗, 击, 新, 型, 肺, 炎, 第, 一, 线, #, 【, @, 中, 国, ...\n",
       "99996    [1, 、, 类, R, a, T, G, 1, 3, 病, 毒, （, 一, 种, 从, ...\n",
       "99997    [#, 微, 博, 辟, 谣, #, 没, 有, 证, 据, 表, 明, ，, 吃, 大, ...\n",
       "99998    [【, 新, 冠, 疫, 情, 最, 受, 关, 注, 的, 十, 一, 篇, 英, 文, ...\n",
       "99999    [从, 蝙, 蝠, 携, 带, 的, 冠, 状, 病, 毒, 变, 异, 成, 2, 0, ...\n",
       "Name: 微博中文内容, Length: 99560, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['微博中文内容']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新',\n",
       " '年',\n",
       " '的',\n",
       " '第',\n",
       " '一',\n",
       " '天',\n",
       " '感',\n",
       " '冒',\n",
       " '又',\n",
       " '发',\n",
       " '烧',\n",
       " '的',\n",
       " '也',\n",
       " '太',\n",
       " '衰',\n",
       " '了',\n",
       " '但',\n",
       " '是',\n",
       " '我',\n",
       " '要',\n",
       " '想',\n",
       " '着',\n",
       " '明',\n",
       " '天',\n",
       " '一',\n",
       " '定',\n",
       " '会',\n",
       " '好',\n",
       " '的',\n",
       " '?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = train_df['微博中文内容'][3]\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新',\n",
       " '年',\n",
       " 1,\n",
       " '第',\n",
       " '一',\n",
       " '天',\n",
       " '感',\n",
       " '冒',\n",
       " '又',\n",
       " '发',\n",
       " '烧',\n",
       " '的',\n",
       " '也',\n",
       " '太',\n",
       " '衰',\n",
       " '了',\n",
       " '但',\n",
       " '是',\n",
       " '我',\n",
       " '要',\n",
       " '想',\n",
       " '着',\n",
       " '明',\n",
       " '天',\n",
       " '一',\n",
       " '定',\n",
       " '会',\n",
       " '好',\n",
       " '的',\n",
       " '?']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['微博中文内容'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-7b3685c7ab87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'微博中文内容'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtiran_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'微博中文内容'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-7b3685c7ab87>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'微博中文内容'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    #print(x)\n",
    "    return list(x)\n",
    "\n",
    "train_df['微博中文内容'].apply(f)\n",
    "tiran_df['微博中文内容']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "UNKNOWN = '<UNK>'\n",
    "PADDING = '<PAD>'\n",
    "\n",
    "def read_pretrain_embedding(emb_path):\n",
    "    pre_train_emd = {}\n",
    "    with open(emb_path, mode='r', encoding='utf-8') as f:\n",
    "        word_nums, dim = f.readline().split()\n",
    "        word_nums = int(word_nums)\n",
    "        dim = int(dim)\n",
    "        for line in f:\n",
    "            tokens = line.strip().split(' ')\n",
    "            if len(tokens) == dim + 1:\n",
    "                pre_train_emd[tokens[0]] = list(map(lambda x: float(x), tokens[1:]))\n",
    "    return pre_train_emd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_emd = read_pretrain_embedding('data/sgns.weibo.char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_data(dataPath, is_train = True):\n",
    "    with open(dataPath, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = list(reader)\n",
    "        data = np.asarray(data)\n",
    "        content_data = {'content':[], 'label':[]}\n",
    "        for line in data:\n",
    "            content_data['content'].append(list(line['微博中文内容']))\n",
    "            if is_train:\n",
    "                content_data['label'].append(line['情感倾向'])\n",
    "        \n",
    "        return content_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ccfd73696751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_weibo_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontent_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test_weibo_clean.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_data' is not defined"
     ]
    }
   ],
   "source": [
    "content_train_data = read_data('data/train_weibo_clean.csv')\n",
    "content_test_data = read_data('data/test_weibo_clean.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99560"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_train_data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_data = content_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_emb(content_train_data, pre_train_emd, emd_dim, content_test_data = None):\n",
    "    \"\"\"\n",
    "        return word_emb type-list [n_vocab * dim]\n",
    "               word2Index type-dict {word: index}\n",
    "    \"\"\"\n",
    "    word_emb = [np.random.uniform(-0.1, 0.1, emd_dim) for _ in range(2)]\n",
    "    word2Index = {PADDING: 0, UNKNOWN: 1}\n",
    "    for content in content_train_data['content']:\n",
    "        for i in range(len(content)):\n",
    "            if content[i] not in word2Index:\n",
    "                if content[i] in pre_train_emd: # in vocab\n",
    "                    word2Index[content[i]] = len(word2Index)\n",
    "                    word_emb.append(pre_train_emd[content[i]])\n",
    "                else: # not in vocab\n",
    "                    content[i] = UNKNOWN\n",
    "            content[i] = word2Index[content[i]]\n",
    "            \n",
    "    if content_test_data is not None:\n",
    "        for content in content_test_data['content']:\n",
    "            for i in range(len(content)):\n",
    "                if content[i] not in word2Index:\n",
    "                    if content[i] in pre_train_emd: # in vocab\n",
    "                        word2Index[content[i]] = len(word2Index)\n",
    "                        word_emb.append(pre_train_emd[content[i]])\n",
    "                    else: # not in vocab\n",
    "                        content[i] = UNKNOWN\n",
    "                content[i] = word2Index[content[i]]\n",
    "    word_emb = np.asarray(word_emb, dtype='float32')\n",
    "    return word_emb, word2Index\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_emb(word_emb, word2Index):\n",
    "    with open('data/word_emb', 'wb') as f:\n",
    "        pickle.dump((word_emb, word2Index), f)\n",
    "    print('saved.')\n",
    "\n",
    "def load_word_emb(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        word_emb, word2Index = pickle.load(f)\n",
    "        return word_emb, word2Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb, word2Index = build_word_emb(content_train_data, pre_train_emd, 300, content_test_data)\n",
    "#save_word_emb(word_emb, word2Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved.\n"
     ]
    }
   ],
   "source": [
    "save_word_emb(word_emb, word2Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb, word2Index = load_word_emb('data/word_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5224, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_content(content_data, seq_len):\n",
    "    pad_seq = np.zeros((len(content_data), seq_len), dtype=int)\n",
    "    for i, row in enumerate(content_data):\n",
    "        doc_len = seq_len\n",
    "        if doc_len > len(row):\n",
    "            doc_len = len(row)\n",
    "        pad_seq[i, :doc_len] = row[:doc_len]\n",
    "    return pad_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 140\n",
    "\n",
    "train_content = pad_content(content_train_data['content'], seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = pad_content(content_test_data['content'], seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train_data['content'] = train_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(content_train_data):\n",
    "    np.random.seed(123)\n",
    "    #np.random.shuffle(content_train_data['content'])\n",
    "    #np.random.shuffle(content_train_data['label'])\n",
    "    length = len(content_train_data['content'])\n",
    "    train_x = content_train_data['content'][:int(0.9 * length)]\n",
    "    train_y = content_train_data['label'][:int(0.9 * length)]\n",
    "    valid_x = content_train_data['content'][int(0.9 * length):]\n",
    "    valid_y = content_train_data['label'][int(0.9 * length):]\n",
    "    train_y = np.asarray(train_y, dtype='int')\n",
    "    valid_y = np.asarray(valid_y, dtype='int')\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y = split_data(content_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y + 1 # 0 neg 1 mid 2 positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y = valid_y + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([16, 140])\n",
      "Sample input: \n",
      " tensor([[ 118,  624,   11,  ...,   94,   95,   70],\n",
      "        [ 229,   15,   16,  ...,   98,    0,    0],\n",
      "        [ 118, 1417, 1157,  ..., 1028,   52,  101],\n",
      "        ...,\n",
      "        [  13,   32, 1378,  ...,  369,   16, 1243],\n",
      "        [ 474,  442,  442,  ...,    0,    0,    0],\n",
      "        [ 442,  442,  162,  ...,    0,    0,    0]])\n",
      "\n",
      "Sample label size:  torch.Size([16])\n",
      "Sample label: \n",
      " tensor([2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    " \n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    " \n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class STModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emd_dim, batch_size, vocab_size, classes_num, hidden_num, layer_num, embeddings = None, padding_idx = 0,dropout=0.5):\n",
    "        super(STModel, self).__init__()\n",
    "        self.hidden_num = hidden_num\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = dropout\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emd_dim = emd_dim\n",
    "        self.encoder = nn.Embedding(vocab_size, emd_dim, padding_idx= padding_idx)\n",
    "        if embeddings is not None:\n",
    "            self.encoder.weight.data.copy_(embeddings)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(emd_dim, hidden_num, layer_num, dropout= dropout,\n",
    "                            bidirectional= False,batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_num, classes_num)\n",
    "        self.init_weights()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        #print(batch_size)\n",
    "        emb = self.drop(self.encoder(x))\n",
    "        #print('emb', emb.size())\n",
    "        lstm_out, hidden = self.lstm(emb, hidden)\n",
    "        #print('lstm_out', lstm_out.size())\n",
    "        lstm_out = self.drop(lstm_out) #lstm_out torch.Size([16, 140, 100]) batch seq hidden \n",
    "        lstm_out = lstm_out.transpose(0, 1)#lstm_out torch.Size([140, 16, 100]) seq batch hidden \n",
    "        fc_input = lstm_out[-1]\n",
    "        #print('fc_input', fc_input.size())\n",
    "        fc_out = self.fc(fc_input)\n",
    "        #print('fc_out', fc_out.size())\n",
    "        sig_out = self.sigm(fc_out)\n",
    "        #print('sig_out', sig_out.size())\n",
    "        pred = sig_out.view(batch_size, -1)\n",
    "        return sig_out\n",
    "    \n",
    "    def print_shape(name, shape):\n",
    "        print('name:', shape)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        #self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        if(train_on_gpu):\n",
    "            return (weight.new_zeros(self.layer_num, batch_size, self.hidden_num).cuda(),\n",
    "                    weight.new_zeros(self.layer_num, batch_size, self.hidden_num).cuda())\n",
    "        else:\n",
    "            return (weight.new_zeros(self.layer_num, batch_size, self.hidden_num),\n",
    "                    weight.new_zeros(self.layer_num, batch_size, self.hidden_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leslie/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "emd_dim = 300\n",
    "vocab_size = word_emb.shape[0]\n",
    "classes_num = 3\n",
    "hidden_num = 100\n",
    "layer_num = 2\n",
    "dropout = 0.5\n",
    "#embeddings = torch.tensor(pickle.load(pkl), dtype=torch.float).to(device)\n",
    "word_emb = torch.tensor(word_emb, dtype=torch.float,requires_grad=False)\n",
    "model = STModel(emd_dim, batch_size, vocab_size, classes_num, hidden_num, layer_num, embeddings = word_emb, dropout = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "SAVE_PATH = 'STMmodel.pt'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "batch_size = 16\n",
    "clip = 5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index: 0\n",
      "batch_index: 1\n",
      "batch_index: 2\n",
      "batch_index: 3\n",
      "batch_index: 4\n",
      "batch_index: 5\n",
      "batch_index: 6\n",
      "batch_index: 7\n",
      "batch_index: 8\n",
      "batch_index: 9\n",
      "batch_index: 10\n",
      "batch_index: 11\n",
      "batch_index: 12\n",
      "batch_index: 13\n",
      "batch_index: 14\n",
      "batch_index: 15\n",
      "batch_index: 16\n",
      "batch_index: 17\n",
      "batch_index: 18\n",
      "batch_index: 19\n",
      "batch_index: 20\n",
      "batch_index: 21\n",
      "batch_index: 22\n",
      "batch_index: 23\n",
      "batch_index: 24\n",
      "batch_index: 25\n",
      "batch_index: 26\n",
      "batch_index: 27\n",
      "batch_index: 28\n",
      "batch_index: 29\n",
      "batch_index: 30\n",
      "batch_index: 31\n",
      "batch_index: 32\n",
      "batch_index: 33\n",
      "batch_index: 34\n",
      "batch_index: 35\n",
      "batch_index: 36\n",
      "batch_index: 37\n",
      "batch_index: 38\n",
      "batch_index: 39\n",
      "batch_index: 40\n",
      "batch_index: 41\n",
      "batch_index: 42\n",
      "batch_index: 43\n",
      "batch_index: 44\n",
      "batch_index: 45\n",
      "batch_index: 46\n",
      "batch_index: 47\n",
      "batch_index: 48\n",
      "batch_index: 49\n",
      "batch_index: 50\n",
      "batch_index: 51\n",
      "batch_index: 52\n",
      "batch_index: 53\n",
      "batch_index: 54\n",
      "batch_index: 55\n",
      "batch_index: 56\n",
      "batch_index: 57\n",
      "batch_index: 58\n",
      "batch_index: 59\n",
      "batch_index: 60\n",
      "batch_index: 61\n",
      "batch_index: 62\n",
      "batch_index: 63\n",
      "batch_index: 64\n",
      "batch_index: 65\n",
      "batch_index: 66\n",
      "batch_index: 67\n",
      "batch_index: 68\n",
      "batch_index: 69\n",
      "batch_index: 70\n",
      "batch_index: 71\n",
      "batch_index: 72\n",
      "batch_index: 73\n",
      "batch_index: 74\n",
      "batch_index: 75\n",
      "batch_index: 76\n",
      "batch_index: 77\n",
      "batch_index: 78\n",
      "batch_index: 79\n",
      "batch_index: 80\n",
      "batch_index: 81\n",
      "batch_index: 82\n",
      "batch_index: 83\n",
      "batch_index: 84\n",
      "batch_index: 85\n",
      "batch_index: 86\n",
      "batch_index: 87\n",
      "batch_index: 88\n",
      "batch_index: 89\n",
      "batch_index: 90\n",
      "batch_index: 91\n",
      "batch_index: 92\n",
      "batch_index: 93\n",
      "batch_index: 94\n",
      "batch_index: 95\n",
      "batch_index: 96\n",
      "batch_index: 97\n",
      "batch_index: 98\n",
      "batch_index: 99\n",
      "batch_index: 100\n",
      "batch_index: 101\n",
      "batch_index: 102\n",
      "batch_index: 103\n",
      "batch_index: 104\n",
      "batch_index: 105\n",
      "batch_index: 106\n",
      "batch_index: 107\n",
      "batch_index: 108\n",
      "batch_index: 109\n",
      "batch_index: 110\n",
      "batch_index: 111\n",
      "batch_index: 112\n",
      "batch_index: 113\n",
      "batch_index: 114\n",
      "batch_index: 115\n",
      "batch_index: 116\n",
      "batch_index: 117\n",
      "batch_index: 118\n",
      "batch_index: 119\n",
      "batch_index: 120\n",
      "batch_index: 121\n",
      "batch_index: 122\n",
      "batch_index: 123\n",
      "batch_index: 124\n",
      "batch_index: 125\n",
      "batch_index: 126\n",
      "batch_index: 127\n",
      "batch_index: 128\n",
      "batch_index: 129\n",
      "batch_index: 130\n",
      "batch_index: 131\n",
      "batch_index: 132\n",
      "batch_index: 133\n",
      "batch_index: 134\n",
      "batch_index: 135\n",
      "batch_index: 136\n",
      "batch_index: 137\n",
      "batch_index: 138\n",
      "batch_index: 139\n",
      "batch_index: 140\n",
      "batch_index: 141\n",
      "batch_index: 142\n",
      "batch_index: 143\n",
      "batch_index: 144\n",
      "batch_index: 145\n",
      "batch_index: 146\n",
      "batch_index: 147\n",
      "batch_index: 148\n",
      "batch_index: 149\n",
      "batch_index: 150\n",
      "batch_index: 151\n",
      "batch_index: 152\n",
      "batch_index: 153\n",
      "batch_index: 154\n",
      "batch_index: 155\n",
      "batch_index: 156\n",
      "batch_index: 157\n",
      "batch_index: 158\n",
      "batch_index: 159\n",
      "batch_index: 160\n",
      "batch_index: 161\n",
      "batch_index: 162\n",
      "batch_index: 163\n",
      "batch_index: 164\n",
      "batch_index: 165\n",
      "batch_index: 166\n",
      "batch_index: 167\n",
      "batch_index: 168\n",
      "batch_index: 169\n",
      "batch_index: 170\n",
      "batch_index: 171\n",
      "batch_index: 172\n",
      "batch_index: 173\n",
      "batch_index: 174\n",
      "batch_index: 175\n",
      "batch_index: 176\n",
      "batch_index: 177\n",
      "batch_index: 178\n",
      "batch_index: 179\n",
      "batch_index: 180\n",
      "batch_index: 181\n",
      "batch_index: 182\n",
      "batch_index: 183\n",
      "batch_index: 184\n",
      "batch_index: 185\n",
      "batch_index: 186\n",
      "batch_index: 187\n",
      "batch_index: 188\n",
      "batch_index: 189\n",
      "batch_index: 190\n",
      "batch_index: 191\n",
      "batch_index: 192\n",
      "batch_index: 193\n",
      "batch_index: 194\n",
      "batch_index: 195\n",
      "batch_index: 196\n",
      "batch_index: 197\n",
      "batch_index: 198\n",
      "batch_index: 199\n",
      "batch_index: 200\n",
      "batch_index: 201\n",
      "batch_index: 202\n",
      "batch_index: 203\n",
      "batch_index: 204\n",
      "batch_index: 205\n",
      "batch_index: 206\n",
      "batch_index: 207\n",
      "batch_index: 208\n",
      "batch_index: 209\n",
      "batch_index: 210\n",
      "batch_index: 211\n",
      "batch_index: 212\n",
      "batch_index: 213\n",
      "batch_index: 214\n",
      "batch_index: 215\n",
      "batch_index: 216\n",
      "batch_index: 217\n",
      "batch_index: 218\n",
      "batch_index: 219\n",
      "batch_index: 220\n",
      "batch_index: 221\n",
      "batch_index: 222\n",
      "batch_index: 223\n",
      "batch_index: 224\n",
      "batch_index: 225\n",
      "batch_index: 226\n",
      "batch_index: 227\n",
      "batch_index: 228\n",
      "batch_index: 229\n",
      "batch_index: 230\n",
      "batch_index: 231\n",
      "batch_index: 232\n",
      "batch_index: 233\n",
      "batch_index: 234\n",
      "batch_index: 235\n",
      "batch_index: 236\n",
      "batch_index: 237\n",
      "batch_index: 238\n",
      "batch_index: 239\n",
      "batch_index: 240\n",
      "batch_index: 241\n",
      "batch_index: 242\n",
      "batch_index: 243\n",
      "batch_index: 244\n",
      "batch_index: 245\n",
      "batch_index: 246\n",
      "batch_index: 247\n",
      "batch_index: 248\n",
      "batch_index: 249\n",
      "batch_index: 250\n",
      "batch_index: 251\n",
      "batch_index: 252\n",
      "batch_index: 253\n",
      "batch_index: 254\n",
      "batch_index: 255\n",
      "batch_index: 256\n",
      "batch_index: 257\n",
      "batch_index: 258\n",
      "batch_index: 259\n",
      "batch_index: 260\n",
      "batch_index: 261\n",
      "batch_index: 262\n",
      "batch_index: 263\n",
      "batch_index: 264\n",
      "batch_index: 265\n",
      "batch_index: 266\n",
      "batch_index: 267\n",
      "batch_index: 268\n",
      "batch_index: 269\n",
      "batch_index: 270\n",
      "batch_index: 271\n",
      "batch_index: 272\n",
      "batch_index: 273\n",
      "batch_index: 274\n",
      "batch_index: 275\n",
      "batch_index: 276\n",
      "batch_index: 277\n",
      "batch_index: 278\n",
      "batch_index: 279\n",
      "batch_index: 280\n",
      "batch_index: 281\n",
      "batch_index: 282\n",
      "batch_index: 283\n",
      "batch_index: 284\n",
      "batch_index: 285\n",
      "batch_index: 286\n",
      "batch_index: 287\n",
      "batch_index: 288\n",
      "batch_index: 289\n",
      "batch_index: 290\n",
      "batch_index: 291\n",
      "batch_index: 292\n",
      "batch_index: 293\n",
      "batch_index: 294\n",
      "batch_index: 295\n",
      "batch_index: 296\n",
      "batch_index: 297\n",
      "batch_index: 298\n",
      "batch_index: 299\n",
      "batch_index: 300\n",
      "batch_index: 301\n",
      "batch_index: 302\n",
      "batch_index: 303\n",
      "batch_index: 304\n",
      "batch_index: 305\n",
      "batch_index: 306\n",
      "batch_index: 307\n",
      "batch_index: 308\n",
      "batch_index: 309\n",
      "batch_index: 310\n",
      "batch_index: 311\n",
      "batch_index: 312\n",
      "batch_index: 313\n",
      "batch_index: 314\n",
      "batch_index: 315\n",
      "batch_index: 316\n",
      "batch_index: 317\n",
      "batch_index: 318\n",
      "batch_index: 319\n",
      "batch_index: 320\n",
      "batch_index: 321\n",
      "batch_index: 322\n",
      "batch_index: 323\n",
      "batch_index: 324\n",
      "batch_index: 325\n",
      "batch_index: 326\n",
      "batch_index: 327\n",
      "batch_index: 328\n",
      "batch_index: 329\n",
      "batch_index: 330\n",
      "batch_index: 331\n",
      "batch_index: 332\n",
      "batch_index: 333\n",
      "batch_index: 334\n",
      "batch_index: 335\n",
      "batch_index: 336\n",
      "batch_index: 337\n",
      "batch_index: 338\n",
      "batch_index: 339\n",
      "batch_index: 340\n",
      "batch_index: 341\n",
      "batch_index: 342\n",
      "batch_index: 343\n",
      "batch_index: 344\n",
      "batch_index: 345\n",
      "batch_index: 346\n",
      "batch_index: 347\n",
      "batch_index: 348\n",
      "batch_index: 349\n",
      "batch_index: 350\n",
      "batch_index: 351\n",
      "batch_index: 352\n",
      "batch_index: 353\n",
      "batch_index: 354\n",
      "batch_index: 355\n",
      "batch_index: 356\n",
      "batch_index: 357\n",
      "batch_index: 358\n",
      "batch_index: 359\n",
      "batch_index: 360\n",
      "batch_index: 361\n",
      "batch_index: 362\n",
      "batch_index: 363\n",
      "batch_index: 364\n",
      "batch_index: 365\n",
      "batch_index: 366\n",
      "batch_index: 367\n",
      "batch_index: 368\n",
      "batch_index: 369\n",
      "batch_index: 370\n",
      "batch_index: 371\n",
      "batch_index: 372\n",
      "batch_index: 373\n",
      "batch_index: 374\n",
      "batch_index: 375\n",
      "batch_index: 376\n",
      "batch_index: 377\n",
      "batch_index: 378\n",
      "batch_index: 379\n",
      "batch_index: 380\n",
      "batch_index: 381\n",
      "batch_index: 382\n",
      "batch_index: 383\n",
      "batch_index: 384\n",
      "batch_index: 385\n",
      "batch_index: 386\n",
      "batch_index: 387\n",
      "batch_index: 388\n",
      "batch_index: 389\n",
      "batch_index: 390\n",
      "batch_index: 391\n",
      "batch_index: 392\n",
      "batch_index: 393\n",
      "batch_index: 394\n",
      "batch_index: 395\n",
      "batch_index: 396\n",
      "batch_index: 397\n",
      "batch_index: 398\n",
      "batch_index: 399\n",
      "batch_index: 400\n",
      "batch_index: 401\n",
      "batch_index: 402\n",
      "batch_index: 403\n",
      "batch_index: 404\n",
      "batch_index: 405\n",
      "batch_index: 406\n",
      "batch_index: 407\n",
      "batch_index: 408\n",
      "batch_index: 409\n",
      "batch_index: 410\n",
      "batch_index: 411\n",
      "batch_index: 412\n",
      "batch_index: 413\n",
      "batch_index: 414\n",
      "batch_index: 415\n",
      "batch_index: 416\n",
      "batch_index: 417\n",
      "batch_index: 418\n",
      "batch_index: 419\n",
      "batch_index: 420\n",
      "batch_index: 421\n",
      "batch_index: 422\n",
      "batch_index: 423\n",
      "batch_index: 424\n",
      "batch_index: 425\n",
      "batch_index: 426\n",
      "batch_index: 427\n",
      "batch_index: 428\n",
      "batch_index: 429\n",
      "batch_index: 430\n",
      "batch_index: 431\n",
      "batch_index: 432\n",
      "batch_index: 433\n",
      "batch_index: 434\n",
      "batch_index: 435\n",
      "batch_index: 436\n",
      "batch_index: 437\n",
      "batch_index: 438\n",
      "batch_index: 439\n",
      "batch_index: 440\n",
      "batch_index: 441\n",
      "batch_index: 442\n",
      "batch_index: 443\n",
      "batch_index: 444\n",
      "batch_index: 445\n",
      "batch_index: 446\n",
      "batch_index: 447\n",
      "batch_index: 448\n",
      "batch_index: 449\n",
      "batch_index: 450\n",
      "batch_index: 451\n",
      "batch_index: 452\n",
      "batch_index: 453\n",
      "batch_index: 454\n",
      "batch_index: 455\n",
      "batch_index: 456\n",
      "batch_index: 457\n",
      "batch_index: 458\n",
      "batch_index: 459\n",
      "batch_index: 460\n",
      "batch_index: 461\n",
      "batch_index: 462\n",
      "batch_index: 463\n",
      "batch_index: 464\n",
      "batch_index: 465\n",
      "batch_index: 466\n",
      "batch_index: 467\n",
      "batch_index: 468\n",
      "batch_index: 469\n",
      "batch_index: 470\n",
      "batch_index: 471\n",
      "batch_index: 472\n",
      "batch_index: 473\n",
      "batch_index: 474\n",
      "batch_index: 475\n",
      "batch_index: 476\n",
      "batch_index: 477\n",
      "batch_index: 478\n",
      "batch_index: 479\n",
      "batch_index: 480\n",
      "batch_index: 481\n",
      "batch_index: 482\n",
      "batch_index: 483\n",
      "batch_index: 484\n",
      "batch_index: 485\n",
      "batch_index: 486\n",
      "batch_index: 487\n",
      "batch_index: 488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index: 489\n",
      "batch_index: 490\n",
      "batch_index: 491\n",
      "batch_index: 492\n",
      "batch_index: 493\n",
      "batch_index: 494\n",
      "batch_index: 495\n",
      "batch_index: 496\n",
      "batch_index: 497\n",
      "batch_index: 498\n",
      "batch_index: 499\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_model() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-4b890943c2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m499\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mval_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%d, %5d] loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_model() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        print('batch_index:', i)\n",
    "        train_input, train_laebl = train_data\n",
    "        if(train_on_gpu):\n",
    "            train_input, train_laebl = train_input.cuda(), train_laebl.cuda()\n",
    "        # forward\n",
    "        hidden = model.init_hidden(batch_size) # 有问题\n",
    "        model.zero_grad()\n",
    "        outputs = model(train_input, hidden)\n",
    "        loss = criterion(outputs, train_laebl)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            evaluate_model(valid_loader,model)\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            with open(SAVE_PATH, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            train_input, labels = data\n",
    "            if(train_on_gpu):\n",
    "                rain_input, labels = rain_input.cuda(), labels.cuda()\n",
    "            outputs = model(train_input)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            train_input = data\n",
    "            outputs = net(train_input)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
