{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"robert.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1a5mAFF0TJe8GJTOjnTnHI08DJWJqHack","authorship_tag":"ABX9TyN1gZ3wxdi1bLEN/D788Iuh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kg9f6egy_tFC","colab_type":"code","outputId":"2c6a4ae0-0c53-43ed-9db9-462f74f584d3","executionInfo":{"status":"ok","timestamp":1585899276221,"user_tz":-480,"elapsed":4982,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":446}},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PRiko-zEABWi","colab_type":"code","colab":{}},"source":["import os\n","path = \"/content/drive/My Drive/NLP/sentiment_compete\"\n","os.chdir(path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKC1ZJpQA9-F","colab_type":"code","colab":{}},"source":["import torch\n","import pandas as pd\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQxApmc1Acse","colab_type":"code","colab":{}},"source":["train_file_path = 'data/train_weibo_clean.csv'\n","train09_file_path = 'data/train_weibo_09.csv'\n","dev01_file_path = 'data/train_weibo_01.csv'\n","bert_model_path = 'robert_base_chinese/pytorch_model.bin'\n","bert_config_path = 'robert_base_chinese/bert_config.json'\n","bert_vocab_path = 'robert_base_chinese/vocab.txt'\n","max_seq_len = 140\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HijPkvZJA8pM","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer,BertConfig"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvQVBOUZBCJD","colab_type":"code","outputId":"6378fceb-19ae-48c3-c913-495a9b8150f1","executionInfo":{"status":"ok","timestamp":1585899304326,"user_tz":-480,"elapsed":3632,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["bert_config = BertConfig.from_pretrained(bert_config_path, output_hidden_states=True)\n","tokenizer = BertTokenizer.from_pretrained(bert_vocab_path)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fS-bOmuaBnOS","colab_type":"code","colab":{}},"source":["def split_data(file_path, rate=0.9):\n","  df = pd.read_csv(file_path)\n","  df = df.iloc[np.random.permutation(len(df))]\n","  train_df = df.iloc[:int(len(df)*rate)]\n","  dev_df = df.iloc[int(len(df)*rate):]\n","  train_df.to_csv('data/train_weibo_09.csv', index=False)\n","  dev_df.to_csv('data/train_weibo_01.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"303fWhunBpaV","colab_type":"code","colab":{}},"source":[" def return_id(str1, truncation_strategy, length):\n","\n","        inputs = tokenizer.encode_plus(str1,\n","            add_special_tokens=True,\n","            max_length=length,\n","            truncation_strategy=truncation_strategy)\n","        \n","        input_ids =  inputs[\"input_ids\"]\n","        input_masks = [1] * len(input_ids)\n","        input_segments = inputs[\"token_type_ids\"]\n","        padding_length = length - len(input_ids)\n","        padding_id = tokenizer.pad_token_id\n","        input_ids = input_ids + ([padding_id] * padding_length)\n","        input_masks = input_masks + ([0] * padding_length)\n","        input_segments = input_segments + ([0] * padding_length)\n","        \n","        return [input_ids, input_masks, input_segments]\n","        \n","def load_data(file_path, tokenizer, max_seq_len, device):\n","  df = pd.read_csv(file_path)\n","  df = df[df['情感倾向'].isin(['0', '1','-1'])]\n","  df = df[['微博中文内容', '情感倾向']]\n","  inputs = tokenize_data(df, tokenizer, '微博中文内容', max_seq_len, device)\n","  outputs = torch.tensor(data=df['情感倾向'].astype(int) + 1, dtype=torch.long, device=device)\n","  return inputs, outputs\n","\n","def tokenize_data(df, tokenizer, column, max_seq_len, device):\n","  input_ids = []\n","  attention_mask = []\n","  token_type_ids = []\n","  for content in tqdm(df[column]):\n","    inputs = tokenizer.encode_plus(text=str(content),\n","                    add_special_tokens=True,\n","                    max_length=max_seq_len,\n","                    truncation_strategy=\"longest_first\",\n","                    return_attention_mask=True,\n","                    pad_to_max_length=True)\n","    ids, masks, token_type_id = inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids']\n","    input_ids.append(ids)\n","    attention_mask.append(masks)\n","    token_type_ids.append(token_type_id) # 3 n len\n","  return torch.tensor(data=[input_ids, attention_mask, token_type_ids], device=device).permute(1, 0, 2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCMS9nryBqbQ","colab_type":"code","outputId":"99811da7-90a4-4f0d-a047-60e39c15b714","executionInfo":{"status":"ok","timestamp":1585885591951,"user_tz":-480,"elapsed":67282,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_data = load_data(train09_file_path, tokenizer, max_seq_len, device)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100%|██████████| 89604/89604 [00:44<00:00, 2006.08it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"N6kj87Q8BvEG","colab_type":"code","outputId":"26ef3cb7-bafa-4446-90fb-d2fce7d80bd8","executionInfo":{"status":"ok","timestamp":1585885597867,"user_tz":-480,"elapsed":66449,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["dev_data = load_data(dev01_file_path, tokenizer, max_seq_len, device)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["100%|██████████| 9956/9956 [00:04<00:00, 2008.87it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NrECwd7YBwnJ","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertModel\n","\n","\n","class RoBertCLSLAST3(nn.Module):\n","    def __init__(self, bert_model_path, config, seq_len):\n","        super(RoBertCLSLAST3, self).__init__()\n","        self.bert_model = BertModel.from_pretrained(bert_model_path, config=config)\n","        self.predict_fc = nn.Sequential(nn.Dropout(p=0.2),\n","                        nn.Linear(config.hidden_size * 2, 512),\n","                        nn.Tanh(),\n","                        nn.Dropout(p=0.2),\n","                        nn.Linear(512, 3)\n","                        )\n","        self.predict_fc.apply(self.init_network)\n","        #for param in self.bert_model.parameters():\n","        #    param.requires_grad = False\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, inputs):\n","        #(batch_size, 3, seq_max_len)i\n","        input_ids = inputs[:, 0] # (batch_size, seq_max_len)\n","        attention_mask = inputs[:, 1] # (batch_size, seq_max_len)\n","        token_type_ids = inputs[:, 2] # (batch_size, seq_max_len)\n","        #(batch_size, sequence_length, hidden_size)\n","        sequence_output, pooler_output, hidden_states = self.bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        attention_mask_pad = attention_mask.unsqueeze(2).permute(0, 2, 1) # (batch_size, 1, seq_len)\n","        \"\"\"\n","        seq_lens = torch.sum(attention_mask, dim=1).unsqueeze(1)# (batch_size, 1)\n","        h13 = self.get_mean(attention_mask_pad, hidden_states[-1], seq_lens)# (batch_size, hidden_size)\n","        h12 = self.get_mean(attention_mask_pad, hidden_states[-2], seq_lens)# (batch_size, hidden_size)\n","        h11 = self.get_mean(attention_mask_pad, hidden_states[-3], seq_lens)# (batch_size, hidden_size)\n","        h10 = self.get_mean(attention_mask_pad, hidden_states[-4], seq_lens)# (batch_size, hidden_size)\n","        concat_hidden = torch.cat([h13, h12, h11, h10], dim=1)#(batch_size, 4, hidden_size)\n","        mean_hidden = concat_hidden.mean(dim=1)#(batch_size, hidden_size)\n","        \"\"\"\n","        mean_cls = (hidden_states[-1][:,0] + hidden_states[-2][:,0] + hidden_states[-3][:,0]) / 3.0\n","        concat_input = torch.cat([pooler_output, mean_cls], dim=1)\n","        outputs = self.predict_fc(concat_input)\n","        return outputs\n","\n","    def get_mean(self, attention_mask_pad, hidden_state, seq_lens):\n","        \"\"\"\n","          hidden_state: (batch_size, seq_len, hidden_size)\n","          seq_lens (batch_size, 1)\n","        \"\"\"\n","        hidden_state_real = hidden_state.permute(0, 2, 1) * attention_mask_pad # (batch_size, hidden_size, seq_len)\n","        hidden_state_real = hidden_state_real.permute(0, 2, 1)# (batch_size, seq_len, hidden_size)\n","        hidden_state_sum = torch.sum(hidden_state_real, dim=1)# (batch_size, hidden_size)\n","        return self.div_with_small_value(hidden_state_sum, seq_lens).unsqueeze(1)\n","\n","    def div_with_small_value(self, a, b, eps=1.0):\n","        b = b * (b > eps).float() + (b <= eps).float() * 1.0\n","        return a / b \n","\n","    def init_network(self, module):\n","        if isinstance(module, nn.Linear):\n","          print(module.__class__.__name__)\n","          nn.init.xavier_uniform_(module.weight.data)\n","          nn.init.constant_(module.bias.data, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYtfWYCLEPmW","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, TensorDataset\n","def train(train_data, dev_data, model, batch_size, num_epochs, model_save_path, lr=0.0001):\n","  train_inputs, train_outputs = train_data\n","  train_dataset = TensorDataset(train_inputs, train_outputs)\n","  start_time = time.time()\n","  optimizer = optim.Adam(model.parameters(), lr=lr)\n","  total_batch = 0\n","  criterion = nn.CrossEntropyLoss()\n","  dev_per_batch = 500\n","  dev_best_loss = float('inf')\n","  last_improve = 0\n","  require_improvement = 1000\n","  model.train()\n","  for epoch in range(num_epochs):\n","    print('epoch [{}/{}]'.format(epoch + 1, num_epochs))\n","    for (inputs, labels) in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n","      total_batch += 1\n","      model.zero_grad() \n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","      if total_batch % dev_per_batch == 0:\n","        true_labels = labels.data.cpu()\n","        predicts = torch.max(outputs.data, dim=1)[1].cpu().numpy()\n","        train_acc = metrics.accuracy_score(true_labels, predicts)\n","        time_dif = get_time_dif(start_time)\n","        dev_acc, dev_loss, report, confusion = evaluate(dev_data, model, batch_size)\n","        model.train()\n","        if dev_best_loss > dev_loss:\n","          dev_best_loss = dev_loss\n","          improve = '*'\n","          torch.save(model.state_dict(), model_save_path)\n","        else:\n","          improve = ' '\n","        msg = 'Epoch:{0:>2} Iter: {1:>6},  Train Loss: {2:>5.2},  Train Acc: {3:>6.2%},' \\\n","                      '  Dev Loss: {4:>5.2},  Dev Acc: {5:>6.2%},  Time: {6} {7}'\n","        print(msg.format(epoch, total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n","      \n","  evaluate(dev_data, model, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0rAEwo7EVa6","colab_type":"code","colab":{}},"source":["def evaluate(dev_data, model, batch_size):\n","  model.eval()\n","  criterion = nn.CrossEntropyLoss()\n","  labels_all = np.array([], dtype=int)\n","  predicts_all = np.array([], dtype=int)\n","  dev_inputs, dev_outputs = dev_data\n","  dev_dataset = TensorDataset(dev_inputs, dev_outputs)\n","  loss_total = 0\n","  with torch.no_grad():\n","    for (inputs, labels) in DataLoader(dataset=dev_dataset, batch_size=batch_size, shuffle=False):\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss_total += loss.item()\n","        predicts = torch.max(outputs.data, dim=1)[1].cpu().numpy()\n","        labels = labels.data.cpu().numpy()\n","        predicts_all = np.append(predicts_all, predicts)\n","        labels_all = np.append(labels_all, labels)\n","  acc = metrics.accuracy_score(labels_all, predicts_all)\n","  report = metrics.classification_report(labels_all, predicts_all, digits=4)\n","  confusion = metrics.confusion_matrix(labels_all, predicts_all)\n","  return acc, loss_total / len(dev_inputs) * batch_size, report, confusion"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1rxBOaiEWsc","colab_type":"code","colab":{}},"source":["def predict(data_x, ids_all, model, batch_size, output_path):\n","    model.load_state_dict(torch.load('save_model/bert_model'))\n","    model.eval()\n","    start_time = time.time()\n","    predicts_all = []\n","    for inputs,_ in tqdm(DataLoader(dataset=data_x, batch_size=batch_size, shuffle=False)):\n","        outputs = model(inputs)\n","        predicts = list(torch.max(outputs.data, dim=1)[1].cpu().numpy() - 1)\n","        predicts_all = predicts_all + predicts\n","\n","    time_dif = get_time_dif(start_time)\n","    print(\"Time usage:\", time_dif)\n","    result_pd = pd.DataFrame(\n","        {\n","            'id': ids_all,\n","            'y': predicts_all\n","        }\n","    )\n","    result_pd.to_csv(output_path, index=False)\n","    print(\"finish !\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z12PQpdQEYBc","colab_type":"code","colab":{}},"source":["import time\n","from datetime import timedelta\n","def get_time_dif(start_time):\n","    \"\"\"获取已使用时间\"\"\"\n","    end_time = time.time()\n","    time_dif = end_time - start_time\n","    return timedelta(seconds=int(round(time_dif)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgD32L-SEZdU","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn import metrics\n","import time\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWjxAL0oEaru","colab_type":"code","outputId":"016ee326-4347-4b73-e9b4-52afe636781c","executionInfo":{"status":"ok","timestamp":1585899396693,"user_tz":-480,"elapsed":12064,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["model = RoBertCLSLAST3(bert_model_path, bert_config, 140).to(device)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Linear\n","Linear\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WQHNAkBUEcIy","colab_type":"code","outputId":"539c7d7b-5d93-467e-8504-d8034f17b3d6","executionInfo":{"status":"error","timestamp":1585752097850,"user_tz":-480,"elapsed":1199,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":836}},"source":["train(train_data, dev_data, model, 16, 10, 'save_model/bert_model', lr=0.00001)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch [1/10]\n","Epoch: 0 Iter:    500,  Train Loss:  0.73,  Train Acc: 56.25%,  Dev Loss:  0.63,  Dev Acc: 72.88%,  Time: 0:06:18 *\n","Epoch: 0 Iter:   1000,  Train Loss:   1.2,  Train Acc: 62.50%,  Dev Loss:  0.59,  Dev Acc: 74.21%,  Time: 0:15:21 *\n","Epoch: 0 Iter:   1500,  Train Loss:  0.61,  Train Acc: 75.00%,  Dev Loss:  0.58,  Dev Acc: 74.71%,  Time: 0:24:12 *\n","Epoch: 0 Iter:   2000,  Train Loss:  0.37,  Train Acc: 81.25%,  Dev Loss:  0.57,  Dev Acc: 74.85%,  Time: 0:33:03 *\n","Epoch: 0 Iter:   2500,  Train Loss:  0.89,  Train Acc: 62.50%,  Dev Loss:  0.58,  Dev Acc: 74.89%,  Time: 0:41:54  \n","Epoch: 0 Iter:   3000,  Train Loss:  0.37,  Train Acc: 81.25%,  Dev Loss:  0.57,  Dev Acc: 75.26%,  Time: 0:50:40 *\n","Epoch: 0 Iter:   3500,  Train Loss:  0.24,  Train Acc: 100.00%,  Dev Loss:  0.59,  Dev Acc: 74.13%,  Time: 0:59:31  \n","Epoch: 0 Iter:   4000,  Train Loss:  0.57,  Train Acc: 75.00%,  Dev Loss:  0.56,  Dev Acc: 75.54%,  Time: 1:08:17 *\n","Epoch: 0 Iter:   4500,  Train Loss:  0.47,  Train Acc: 81.25%,  Dev Loss:  0.57,  Dev Acc: 75.47%,  Time: 1:17:08  \n","Epoch: 0 Iter:   5000,  Train Loss:  0.58,  Train Acc: 62.50%,  Dev Loss:  0.58,  Dev Acc: 75.00%,  Time: 1:25:54  \n","Epoch: 0 Iter:   5500,  Train Loss:  0.61,  Train Acc: 68.75%,  Dev Loss:  0.59,  Dev Acc: 74.06%,  Time: 1:34:41  \n","epoch [2/10]\n","Epoch: 1 Iter:   6000,  Train Loss:   0.3,  Train Acc: 81.25%,  Dev Loss:   0.6,  Dev Acc: 75.62%,  Time: 1:43:26  \n","Epoch: 1 Iter:   6500,  Train Loss:  0.38,  Train Acc: 81.25%,  Dev Loss:  0.61,  Dev Acc: 76.02%,  Time: 1:52:12  \n","Epoch: 1 Iter:   7000,  Train Loss:   0.6,  Train Acc: 87.50%,  Dev Loss:  0.59,  Dev Acc: 75.84%,  Time: 2:00:58  \n","Epoch: 1 Iter:   7500,  Train Loss:  0.32,  Train Acc: 81.25%,  Dev Loss:   0.6,  Dev Acc: 75.62%,  Time: 2:09:44  \n","Epoch: 1 Iter:   8000,  Train Loss:  0.41,  Train Acc: 87.50%,  Dev Loss:  0.59,  Dev Acc: 75.53%,  Time: 2:18:30  \n","Epoch: 1 Iter:   8500,  Train Loss:  0.39,  Train Acc: 81.25%,  Dev Loss:  0.58,  Dev Acc: 75.71%,  Time: 2:27:16  \n","Epoch: 1 Iter:   9000,  Train Loss:  0.46,  Train Acc: 75.00%,  Dev Loss:  0.59,  Dev Acc: 75.82%,  Time: 2:36:02  \n","Epoch: 1 Iter:   9500,  Train Loss:  0.47,  Train Acc: 75.00%,  Dev Loss:   0.6,  Dev Acc: 74.93%,  Time: 2:44:48  \n","Epoch: 1 Iter:  10000,  Train Loss:  0.72,  Train Acc: 75.00%,  Dev Loss:  0.57,  Dev Acc: 75.86%,  Time: 2:53:34  \n","Epoch: 1 Iter:  10500,  Train Loss:  0.68,  Train Acc: 62.50%,  Dev Loss:  0.59,  Dev Acc: 75.83%,  Time: 3:02:21  \n","Epoch: 1 Iter:  11000,  Train Loss:  0.73,  Train Acc: 75.00%,  Dev Loss:  0.56,  Dev Acc: 76.19%,  Time: 3:11:07 *\n","epoch [3/10]\n","Epoch: 2 Iter:  11500,  Train Loss:  0.28,  Train Acc: 87.50%,  Dev Loss:  0.68,  Dev Acc: 75.87%,  Time: 3:19:58  \n","Epoch: 2 Iter:  12000,  Train Loss:  0.54,  Train Acc: 68.75%,  Dev Loss:  0.63,  Dev Acc: 75.36%,  Time: 3:28:44  \n","Epoch: 2 Iter:  12500,  Train Loss:  0.35,  Train Acc: 93.75%,  Dev Loss:  0.67,  Dev Acc: 74.67%,  Time: 3:37:30  \n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-fc32e797f31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'save_model/bert_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-504860eae8a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, dev_data, model, batch_size, num_epochs, model_save_path, lr)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdev_per_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"NoedswktFMWX","colab_type":"code","colab":{}},"source":["def load_test_data(file_path, tokenizer, max_seq_len, device):\n","  df = pd.read_csv(file_path)\n","  df = df[['微博中文内容']]\n","  inputs = tokenize_data(df, tokenizer, '微博中文内容', max_seq_len, device)\n","  return inputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_rmzDgYFWCD","colab_type":"code","outputId":"04cc7c99-050f-4d24-96c4-d354f1698f46","executionInfo":{"status":"ok","timestamp":1585899413439,"user_tz":-480,"elapsed":7706,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_input = load_test_data('data/test_weibo_clean.csv', tokenizer, max_seq_len, device)\n","test_df = pd.read_csv('data/test_weibo_clean.csv')\n","test_tensor = TensorDataset(test_input, torch.rand(test_input.size()[0]))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:05<00:00, 1938.24it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tb_Tba_3-MYC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"ebba84ef-cc2a-459e-9705-f09508df96cd","executionInfo":{"status":"ok","timestamp":1585899653058,"user_tz":-480,"elapsed":187106,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}}},"source":["predict(test_tensor, test_df['微博id'], model, 16, 'bert_ans.csv')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 625/625 [02:30<00:00,  4.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Time usage: 0:02:30\n","finish !\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"s_aTcq7gpDLe","colab_type":"code","outputId":"fff049d2-9889-4e62-e270-294223bdd966","executionInfo":{"status":"ok","timestamp":1585885344982,"user_tz":-480,"elapsed":3812,"user":{"displayName":"Rong Leslie","photoUrl":"","userId":"04972105603495756887"}},"colab":{"base_uri":"https://localhost:8080/","height":284}},"source":["!ps -aux"],"execution_count":22,"outputs":[{"output_type":"stream","text":["USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n","root           1  0.0  0.0  39192  6308 ?        Ss   03:32   0:00 /bin/bash -e \n","root           8  0.2  0.3 681620 50280 ?        Sl   03:32   0:01 /tools/node/b\n","root          18  0.5  0.7 405212 101224 ?       Sl   03:32   0:03 /usr/bin/pyth\n","root         114  0.0  0.0  35888  4804 ?        Ss   03:33   0:00 tail -n +0 -F\n","root         122 13.6 44.2 31220748 5899048 ?    Ssl  03:33   1:10 /usr/bin/pyth\n","root         158  0.0  0.0  18376  1500 ?        S    03:33   0:00 /bin/bash --n\n","root         159  0.0  0.1 1124572 15288 ?       Sl   03:33   0:00 /opt/google/d\n","root         160  0.0  0.0  11464  1024 ?        S    03:33   0:00 grep --color=\n","root         162  1.8  0.5 2495036 70076 ?       Sl   03:33   0:09 /opt/google/d\n","root         176  0.0  0.0      0     0 ?        Z    03:34   0:00 [fusermount] \n","root         212  0.0  0.0  18376  3088 ?        S    03:34   0:00 bash -c tail \n","root         213  0.0  0.0   4568   768 ?        S    03:34   0:00 tail -n +0 -F\n","root         214  0.0  0.0  11464  1024 ?        S    03:34   0:00 grep --line-b\n","root         407  0.0  0.0  59032  6260 ?        R    03:42   0:00 ps -aux\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hnPsSMrpHZY","colab_type":"code","colab":{}},"source":["!kill -9 122"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_7yehvzpurN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}